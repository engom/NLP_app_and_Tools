{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff192e89",
   "metadata": {},
   "source": [
    "# TEXT PREPROCESSING \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e5501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5216ee08",
   "metadata": {},
   "source": [
    "### Reading the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf91b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff925f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would love to stay at CW because I really lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CW is a wonderful place to work in ,salary is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Even if I do plan to stay for the experience, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>its will great to stay with CW but you get sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am constantly seeking new challenges and my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Working environment is conducive, good team wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CW is a moving train that improves every quart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>There is room for career growth and developmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It is mentally stressful, this is because, we ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response\n",
       "0  I would love to stay at CW because I really lo...\n",
       "1  CW is a wonderful place to work in ,salary is ...\n",
       "2  Even if I do plan to stay for the experience, ...\n",
       "3  its will great to stay with CW but you get sta...\n",
       "4  I am constantly seeking new challenges and my ...\n",
       "5  Working environment is conducive, good team wo...\n",
       "6  CW is a moving train that improves every quart...\n",
       "7  There is room for career growth and developmen...\n",
       "8  It is mentally stressful, this is because, we ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text = pd.read_csv(r'C:\\Users\\SD-16\\Downloads\\text_data_pratice.csv')\n",
    "df_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da3e4ae",
   "metadata": {},
   "source": [
    "# Lowercasing\n",
    "##### \n",
    "The lowercasing is an important text preprocessing step in which we convert the text into the same casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bdb3579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i would love to stay at cw because i really lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cw is a wonderful place to work in ,salary is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>even if i do plan to stay for the experience, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>its will great to stay with cw but you get sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am constantly seeking new challenges and my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response\n",
       "0  i would love to stay at cw because i really lo...\n",
       "1  cw is a wonderful place to work in ,salary is ...\n",
       "2  even if i do plan to stay for the experience, ...\n",
       "3  its will great to stay with cw but you get sta...\n",
       "4  i am constantly seeking new challenges and my ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['response']=df_text['response'].str.lower()\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5597a94",
   "metadata": {},
   "source": [
    "##  Remove Extra Whitespaces\n",
    "\n",
    "A text may contain extra whitespace which is not desired as they increase the text size and not add any value to the data\n",
    "In Python, we can do this by splitting the text and joining it back on the basis of single whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a3af8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i would love to stay at cw because i really lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cw is a wonderful place to work in ,salary is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>even if i do plan to stay for the experience, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>its will great to stay with cw but you get sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am constantly seeking new challenges and my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>working environment is conducive, good team wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cw is a moving train that improves every quart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>there is room for career growth and developmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it is mentally stressful, this is because, we ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response\n",
       "0  i would love to stay at cw because i really lo...\n",
       "1  cw is a wonderful place to work in ,salary is ...\n",
       "2  even if i do plan to stay for the experience, ...\n",
       "3  its will great to stay with cw but you get sta...\n",
       "4  i am constantly seeking new challenges and my ...\n",
       "5  working environment is conducive, good team wo...\n",
       "6  cw is a moving train that improves every quart...\n",
       "7  there is room for career growth and developmen...\n",
       "8  it is mentally stressful, this is because, we ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "\n",
    "df_text['response']=df_text['response'].apply(remove_whitespace)\n",
    "df_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11714b4",
   "metadata": {},
   "source": [
    "## Tokenization \n",
    "\n",
    "\n",
    "This is the process of splitting text into pieces called tokens. \n",
    "A corpus of text can be converted into tokens of sentences, words, or even characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd8041b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i, would, love, to, stay, at, cw, because, i,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[cw, is, a, wonderful, place, to, work, in, ,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[even, if, i, do, plan, to, stay, for, the, ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[its, will, great, to, stay, with, cw, but, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[i, am, constantly, seeking, new, challenges, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response\n",
       "0  [i, would, love, to, stay, at, cw, because, i,...\n",
       "1  [cw, is, a, wonderful, place, to, work, in, ,,...\n",
       "2  [even, if, i, do, plan, to, stay, for, the, ex...\n",
       "3  [its, will, great, to, stay, with, cw, but, yo...\n",
       "4  [i, am, constantly, seeking, new, challenges, ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "df_text['response']=df_text['response'].apply(lambda X: word_tokenize(X))\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0925052f",
   "metadata": {},
   "source": [
    "## Spelling correction\n",
    "\n",
    "\n",
    "This ensures we get better results from our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3556ccbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'indexer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-40335c028e49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mspellchecker\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSpellChecker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mspell_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mspell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpellChecker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spellchecker\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# -*- coding: utf-8 -*-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m  \u001b[0mspellchecker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSpellchecker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgetInstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spellchecker\\core.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDictionaryIndex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangdetect\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_detect_lang\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'indexer'"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "def spell_check(text):\n",
    "    \n",
    "    result = []\n",
    "    spell = SpellChecker()\n",
    "    for word in text:\n",
    "        correct_word = spell.correction(word)\n",
    "        result.append(correct_word)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747354fd",
   "metadata": {},
   "source": [
    "## Stop words\n",
    "\n",
    "Stopwords are trivial words like “I”, “the”, “you”, etc. that appear so frequently in the text that they may distort \\\n",
    "many NLP operations without adding much valuable information. \\\n",
    "So almost always you will have to remove stopwords from the corpus as part of your preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e96d79d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "792f5e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    result = []\n",
    "    for token in text:\n",
    "        if token not in en_stopwords:\n",
    "            result.append(token)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59f0d73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[would, love, stay, cw, really, love, ., howev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[cw, wonderful, place, work, ,, salary, attrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[even, plan, stay, experience, ,, terms, job, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[great, stay, cw, get, stagnated, single, spot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[constantly, seeking, new, challenges, stay, d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response\n",
       "0  [would, love, stay, cw, really, love, ., howev...\n",
       "1  [cw, wonderful, place, work, ,, salary, attrac...\n",
       "2  [even, plan, stay, experience, ,, terms, job, ...\n",
       "3  [great, stay, cw, get, stagnated, single, spot...\n",
       "4  [constantly, seeking, new, challenges, stay, d..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['response'] = df_text['response'].apply(remove_stopwords)\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cad0b8",
   "metadata": {},
   "source": [
    "## Removing Punctuations\n",
    "\n",
    "Removing punctuation is an important text preprocessing step as it also does not add any value to the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd256b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def remove_punct(text):\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    lst=tokenizer.tokenize(' '.join(text))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "073404b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[would, love, stay, cw, really, love, however,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[cw, wonderful, place, work, salary, attractiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[even, plan, stay, experience, terms, job, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[great, stay, cw, get, stagnated, single, spot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[constantly, seeking, new, challenges, stay, d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response\n",
       "0  [would, love, stay, cw, really, love, however,...\n",
       "1  [cw, wonderful, place, work, salary, attractiv...\n",
       "2  [even, plan, stay, experience, terms, job, con...\n",
       "3  [great, stay, cw, get, stagnated, single, spot...\n",
       "4  [constantly, seeking, new, challenges, stay, d..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['response'] = df_text['response'].apply(remove_punct)\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4e9915",
   "metadata": {},
   "source": [
    "## Removal of Accented Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b307165e",
   "metadata": {},
   "source": [
    "Accented characters are important elements which are used to signify emphasis on a particular word during pronunciation or understanding. In some instances, the accent mark also clarifies the meaning of a word, which might be different without the accent. While their use in English is largely limited but there are very good chances that you will come across accented characters/letters in a free text corpus. Words such as résumé, café, prótest, divorcé, coördinate, exposé, latté etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9146cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import unicodedata\n",
    "# function to remove accented characters\n",
    "def remove_accented_chars(text):\n",
    "    new_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return new_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95820f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some Accented text. Some words such as resume, cafe, protest, divorce, coordinate, expose, latte.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call function\n",
    "remove_accented_chars('Sómě Áccěntěd těxt. Some words such as résumé, café, prótest, divorcé, coördinate, exposé, latté.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7e0b99",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aac908",
   "metadata": {},
   "source": [
    "## Expanding contraction words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fccaa5",
   "metadata": {},
   "source": [
    "Nowadays, many editors will induce contractions by default. For examples do not to don’t, I would to I’d, you are to you’re. Converting each contraction to its expanded, original form helps with text standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9789208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pycontractions import Contractions\n",
    "cont = Contractions(kv_model=model)\n",
    "cont.load_models()\n",
    "# function to expand contractions\n",
    "def expand_contractions(text):\n",
    "    text = list(cont.expand_texts([text], precise=True))[0]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function \n",
    "expand_contractions(“Y’all i’d contractions you’re expanded don’t think.”)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9d75c2",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d777580",
   "metadata": {},
   "source": [
    "Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b228ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize,pos_tag\n",
    "\n",
    "def lemmatization(text):\n",
    "    \n",
    "    result=[]\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    for token in text:\n",
    "        result.append(wordnet.lemmatize(token))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a514b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[would, love, stay, cw, really, love, however, thinking, fact, best, job, last, 3, year, without, real, growth, career, wise, bit, discouraging, still, thing, since, came, despite, many, recongnition, commendation, happy, working]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[cw, wonderful, place, work, salary, attractive, secure, neat, conducive, working, environment, management, employee, heart, mould, character, relate, provide, solution, problem, arising, others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[even, plan, stay, experience, term, job, constantly, keep, toe, constantly, seeking, employment, elsewhere, afford, sudden, termination, due, performance, ve, got, bill, sort, department, good, place, stay, long, toxic, nature, job, n, t, one, deal, long, mental, emotional, stability, real, thing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[great, stay, cw, get, stagnated, single, spot, long, time, create, temptation, leaving, get, better, offer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[constantly, seeking, new, challenge, stay, depends, valuable, company, find, always, seek, improve, work, ethic, place, good, stead, leadership, position]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                      response\n",
       "0  [would, love, stay, cw, really, love, however, thinking, fact, best, job, last, 3, year, without, real, growth, career, wise, bit, discouraging, still, thing, since, came, despite, many, recongnition, commendation, happy, working]                                                                     \n",
       "1  [cw, wonderful, place, work, salary, attractive, secure, neat, conducive, working, environment, management, employee, heart, mould, character, relate, provide, solution, problem, arising, others]                                                                                                        \n",
       "2  [even, plan, stay, experience, term, job, constantly, keep, toe, constantly, seeking, employment, elsewhere, afford, sudden, termination, due, performance, ve, got, bill, sort, department, good, place, stay, long, toxic, nature, job, n, t, one, deal, long, mental, emotional, stability, real, thing]\n",
       "3  [great, stay, cw, get, stagnated, single, spot, long, time, create, temptation, leaving, get, better, offer]                                                                                                                                                                                               \n",
       "4  [constantly, seeking, new, challenge, stay, depends, valuable, company, find, always, seek, improve, work, ethic, place, good, stead, leadership, position]                                                                                                                                                "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['response']=df_text['response'].apply(lemmatization)\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dbe47c",
   "metadata": {},
   "source": [
    "This looks quite naive. words are still ending with -ing, ed, ly and this is not supposed to be so\n",
    "\n",
    "So, now, we will make use of POS argument and try to lemmatize again and test a few variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca9d6362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize,pos_tag\n",
    "\n",
    "def lemmatization(text):\n",
    "    \n",
    "    result=[]\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    for token,tag in pos_tag(text):\n",
    "        pos=tag[0].lower()\n",
    "        \n",
    "        if pos not in ['a', 'r', 'n', 'v']:\n",
    "            pos='n'\n",
    "            \n",
    "        result.append(wordnet.lemmatize(token,pos))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fbab7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[would, love, stay, cw, really, love, however, think, fact, best, job, last, 3, year, without, real, growth, career, wise, bit, discourage, still, thing, since, come, despite, many, recongnition, commendation, happy, working]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[cw, wonderful, place, work, salary, attractive, secure, neat, conducive, work, environment, management, employee, heart, mould, character, relate, provide, solution, problem, arise, others]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[even, plan, stay, experience, term, job, constantly, keep, toe, constantly, seek, employment, elsewhere, afford, sudden, termination, due, performance, ve, get, bill, sort, department, good, place, stay, long, toxic, nature, job, n, t, one, deal, long, mental, emotional, stability, real, thing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[great, stay, cw, get, stagnate, single, spot, long, time, create, temptation, leave, get, better, offer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[constantly, seek, new, challenge, stay, depend, valuable, company, find, always, seek, improve, work, ethic, place, good, stead, leadership, position]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                   response\n",
       "0  [would, love, stay, cw, really, love, however, think, fact, best, job, last, 3, year, without, real, growth, career, wise, bit, discourage, still, thing, since, come, despite, many, recongnition, commendation, happy, working]                                                                       \n",
       "1  [cw, wonderful, place, work, salary, attractive, secure, neat, conducive, work, environment, management, employee, heart, mould, character, relate, provide, solution, problem, arise, others]                                                                                                          \n",
       "2  [even, plan, stay, experience, term, job, constantly, keep, toe, constantly, seek, employment, elsewhere, afford, sudden, termination, due, performance, ve, get, bill, sort, department, good, place, stay, long, toxic, nature, job, n, t, one, deal, long, mental, emotional, stability, real, thing]\n",
       "3  [great, stay, cw, get, stagnate, single, spot, long, time, create, temptation, leave, get, better, offer]                                                                                                                                                                                               \n",
       "4  [constantly, seek, new, challenge, stay, depend, valuable, company, find, always, seek, improve, work, ethic, place, good, stead, leadership, position]                                                                                                                                                 "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['response']=df_text['response'].apply(lemmatization)\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7e9e08",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Stemming is used to reduce different grammatical forms or word forms of a word like its noun, adjective, verb, adverb etc. to its root form. Computationally, it is a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. It is important for information retrieval systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d592c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Porter Stemmer implementation in nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def stemming(text):\n",
    "    porter = PorterStemmer()\n",
    "    \n",
    "    result=[]\n",
    "    for word in text:\n",
    "        result.append(porter.stem(word))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc58456b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[would, love, stay, cw, realli, love, howev, think, fact, best, job, last, 3, year, without, real, growth, career, wise, bit, discourag, still, thing, sinc, come, despit, mani, recongnit, commend, happi, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[cw, wonder, place, work, salari, attract, secur, neat, conduc, work, environ, manag, employe, heart, mould, charact, relat, provid, solut, problem, aris, other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[even, plan, stay, experi, term, job, constantli, keep, toe, constantli, seek, employ, elsewher, afford, sudden, termin, due, perform, ve, get, bill, sort, depart, good, place, stay, long, toxic, natur, job, n, t, one, deal, long, mental, emot, stabil, real, thing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[great, stay, cw, get, stagnat, singl, spot, long, time, creat, temptat, leav, get, better, offer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[constantli, seek, new, challeng, stay, depend, valuabl, compani, find, alway, seek, improv, work, ethic, place, good, stead, leadership, posit]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                    response\n",
       "0  [would, love, stay, cw, realli, love, howev, think, fact, best, job, last, 3, year, without, real, growth, career, wise, bit, discourag, still, thing, sinc, come, despit, mani, recongnit, commend, happi, work]                                                        \n",
       "1  [cw, wonder, place, work, salari, attract, secur, neat, conduc, work, environ, manag, employe, heart, mould, charact, relat, provid, solut, problem, aris, other]                                                                                                        \n",
       "2  [even, plan, stay, experi, term, job, constantli, keep, toe, constantli, seek, employ, elsewher, afford, sudden, termin, due, perform, ve, get, bill, sort, depart, good, place, stay, long, toxic, natur, job, n, t, one, deal, long, mental, emot, stabil, real, thing]\n",
       "3  [great, stay, cw, get, stagnat, singl, spot, long, time, creat, temptat, leav, get, better, offer]                                                                                                                                                                       \n",
       "4  [constantli, seek, new, challeng, stay, depend, valuabl, compani, find, alway, seek, improv, work, ethic, place, good, stead, leadership, posit]                                                                                                                         "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['response']=df_text['response'].apply(stemming)\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56519089",
   "metadata": {},
   "source": [
    "Note: Stemming is rule based and thus we can see the changes like \"realli\" and \"howev\" in index 0 which does not make sense. Also, notice all the words are already transformed into lower case. This poses a challenge for proper noun detection because the only significant physical notation - the first letter in upper case - will not more be in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f29a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
